{% extends "base.html" %}
{% block content %}

<br>
<p> This year I revisited my <a href='github.com/alexanderbcook/twitter_stream' > twitter stream </a> with two goals in mind - I wanted to improve data fidelity and throughput. Last year, I was not doing 
enough data cleansing and I ended up having to do a ton of manual work to the dataset. A lot of this was due to not encoding the tweets in utf-8, so Emojis and letters from foreign alphabets were troublesome
Additionally, last year, my program crashed due to read/write limitations of my machine. To improve performance, I split read and write into two different mechanisms- the first is a listener which reads tweets
from the Twitter API and shoves them into a Redis queue- the second piece is the writer, which pulls the same information out from Redis and writes to JSON files.</p>

<p>I was pleased with the result. This is a video of the program streaming about 5k/tweets per minute to the file. 
The left pane is a Redis monitor, which just prints push/pull operations. The middle and right panes are two instances of the program, streaming tweets mentioning the Eagles or Patriots.
Both files, over the course of the Superbowl, grew to about 150mb - 4,000,000 tweets in total. All in all, the effort to refactor this code was successful and I am pleased with how it turned out.
</p>
<hr>
<iframe style="display: block; margin: auto;" width="560" height="315" viewbox="0 0 315 560" src="https://www.youtube.com/embed/_SDNNC1YP_w" frameborder="5" allow="encrypted-media" allowfullscreen></iframe>
<hr>
<br>
<p>To celebrate the inclusion of Emojis in the dataset, I decided to graph the dominant Emojis in the respective fan bases over the course of the game.</p>

{% endblock %}

